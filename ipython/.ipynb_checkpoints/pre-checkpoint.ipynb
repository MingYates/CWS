{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-09T12:26:00.032921Z",
     "start_time": "2018-08-09T12:25:57.528359Z"
    }
   },
   "outputs": [],
   "source": [
    "def bieu(sent):\n",
    "    sent = sent.strip()\n",
    "    words = sent.split(' ')\n",
    "    words = [w for w in words if len(w) > 0]\n",
    "    tags = []\n",
    "    for w in words:\n",
    "        wtag = []\n",
    "        if len(w) > 1:\n",
    "            wtag = ['I'] * len(w)\n",
    "            wtag[0] = 'B'\n",
    "            wtag[-1] = 'E'\n",
    "        elif len(w) == 1:\n",
    "            wtag = ['U']\n",
    "        else:\n",
    "            pass\n",
    "        tags.extend(wtag)\n",
    "    return tags\n",
    "\n",
    "\n",
    "full = list(u'０１２３４５６７８９ａｂｃｄｅｆｇｈｉｊｋｌｍｎｏｐｑｒｓｔｕｖｗｘｙｚ、，；‘’“”。？！－：（）％／')\n",
    "half = list(u'0123456789abcdefghijklmnopqrstuvwxyz､,;‘’“”｡?!-:()%/')\n",
    "rdict = dict([(k,v) for k,v in zip(half, full)])\n",
    "def repchar(_line):\n",
    "    result = _line\n",
    "    for k,v in rdict.items():\n",
    "        result = result.replace(k, v)\n",
    "    return result\n",
    "\n",
    "def chunkcut(sent, maxlen=64):\n",
    "    result = []\n",
    "    for i in range(int(len(sent)/maxlen)):\n",
    "        result.append(sent[i*maxlen:(i+1)*64])\n",
    "    return result\n",
    "    \n",
    "def pnsplit(line, maxlen=64):\n",
    "    # u'。！？：；…、，'\n",
    "    sgns = ['。', '！', '？', '：', '；', '，']\n",
    "    resline = line\n",
    "    for s in sgns:\n",
    "        resline = resline.replace(s, s+'\\n')\n",
    "    sents = resline.split('\\n')\n",
    "    result = []\n",
    "    for s in sents:\n",
    "        if len(s) > 0:\n",
    "            if len(s) > maxlen:\n",
    "                result.extend(chunkcut(s))\n",
    "            else:\n",
    "                result.append(s)\n",
    "    return result\n",
    "\n",
    "# s = '王思斌  ，  男  ，  １９４９年１０月  生  。'\n",
    "# print(pnsplit(s))\n",
    "\n",
    "def dealcorp(fpath):\n",
    "    dfile = open(fpath + '.delt', 'w+', encoding='utf8')\n",
    "    with open(fpath, 'r+', encoding='utf8') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            line = line.replace('\\u3000', ' ')\n",
    "            line = repchar(line)\n",
    "            for _l in pnsplit(line):\n",
    "                dfile.write(_l + '\\n')\n",
    "    dfile.close()\n",
    "\n",
    "def gentags(fpath):\n",
    "    tagfile = open(fpath + '.tag', 'w+', encoding='utf8')\n",
    "    with open(fpath, 'r+', encoding='utf8') as f:\n",
    "        for line in f:\n",
    "            tags = bieu(line)\n",
    "            tagfile.write(''.join(tags) + '\\n')\n",
    "    tagfile.close()\n",
    "    \n",
    "# trainpath = '/home/faust/PROJECTS/NEUTAG/data/PKU/pku_training.utf8'\n",
    "# testpath = '/home/faust/PROJECTS/NEUTAG/data/PKU/pku_test_gold.utf8'\n",
    "# trainpath = '/home/faust/PROJECTS/NEUTAG/data/AS/as_training.utf8'\n",
    "# testpath = '/home/faust/PROJECTS/NEUTAG/data/AS/as_testing_gold.utf8'\n",
    "trainpath = '/home/faust/PROJECTS/NEUTAG/data/CITYU/cityu_training.utf8'\n",
    "testpath = '/home/faust/PROJECTS/NEUTAG/data/CITYU/cityu_test_gold.utf8'\n",
    "# trainpath = '/home/faust/PROJECTS/NEUTAG/data/MSR/msr_training.utf8'\n",
    "# testpath = '/home/faust/PROJECTS/NEUTAG/data/MSR/msr_test_gold.utf8'\n",
    "\n",
    "dealcorp(trainpath)\n",
    "dealcorp(testpath)\n",
    "\n",
    "gentags(trainpath + '.delt')\n",
    "gentags(testpath + '.delt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-08-08T12:29:01.644Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165289\n",
      "165289\n",
      "165289\n",
      "(['立', '會', '選', '情', '告', '一', '段', '落', '民', '主', '進', '程', '還', '看', '明', '天'], ['B', 'E', 'B', 'E', 'B', 'I', 'I', 'E', 'B', 'E', 'B', 'E', 'U', 'U', 'B', 'E'])\n",
      "4797\n",
      "4797\n",
      "4797\n",
      "(['\\ufeff', '「', '練', '得', '銅', '皮', '鐵', '骨', '」', '露', '宿', '早', '慣', '蚊', '叮'], ['B', 'E', 'U', 'U', 'B', 'I', 'I', 'E', 'U', 'B', 'E', 'U', 'U', 'B', 'E'])\n"
     ]
    }
   ],
   "source": [
    "def pack(sentpath, tagpath):\n",
    "    sentf = open(sentpath, 'r+', encoding='utf8')\n",
    "    tagf = open(tagpath, 'r+', encoding='utf8')\n",
    "    slines = sentf.readlines()\n",
    "    print(len(slines))\n",
    "    tlines = tagf.readlines()\n",
    "    print(len(tlines))\n",
    "\n",
    "    dump = []\n",
    "    for i in range(len(slines)):\n",
    "        sent = slines[i]\n",
    "        tag = tlines[i]\n",
    "        sent = sent.strip()\n",
    "        tag = tag.strip()\n",
    "        sent = ''.join(sent.split(' '))\n",
    "        if len(sent.strip()) > 0 and len(sent) == len(tag):\n",
    "            dump.append((list(sent), list(tag)))\n",
    "\n",
    "    print(len(dump))\n",
    "    print(dump[0])\n",
    "    return dump\n",
    "\n",
    "# train_sentfile = '/home/faust/PROJECTS/NEUTAG/data/PKU/pku_training.utf8.delt'\n",
    "# train_tagfile = '/home/faust/PROJECTS/NEUTAG/data/PKU/pku_training.utf8.delt.tag'\n",
    "# test_sentfile = '/home/faust/PROJECTS/NEUTAG/data/PKU/pku_test_gold.utf8.delt'\n",
    "# test_tagfile = '/home/faust/PROJECTS/NEUTAG/data/PKU/pku_test_gold.utf8.delt.tag'\n",
    "# train_sentfile = '/home/faust/PROJECTS/NEUTAG/data/AS/as_training.utf8.delt'\n",
    "# train_tagfile = '/home/faust/PROJECTS/NEUTAG/data/AS/as_training.utf8.delt.tag'\n",
    "# test_sentfile = '/home/faust/PROJECTS/NEUTAG/data/AS/as_testing_gold.utf8.delt'\n",
    "# test_tagfile = '/home/faust/PROJECTS/NEUTAG/data/AS/as_testing_gold.utf8.delt.tag'\n",
    "train_sentfile = '/home/faust/PROJECTS/NEUTAG/data/CITYU/cityu_training.utf8.delt'\n",
    "train_tagfile = '/home/faust/PROJECTS/NEUTAG/data/CITYU/cityu_training.utf8.delt.tag'\n",
    "test_sentfile = '/home/faust/PROJECTS/NEUTAG/data/CITYU/cityu_test_gold.utf8.delt'\n",
    "test_tagfile = '/home/faust/PROJECTS/NEUTAG/data/CITYU/cityu_test_gold.utf8.delt.tag'\n",
    "# train_sentfile = '/home/faust/PROJECTS/NEUTAG/data/MSR/msr_training.utf8.delt'\n",
    "# train_tagfile = '/home/faust/PROJECTS/NEUTAG/data/MSR/msr_training.utf8.delt.tag'\n",
    "# test_sentfile = '/home/faust/PROJECTS/NEUTAG/data/MSR/msr_test_gold.utf8.delt'\n",
    "# test_tagfile = '/home/faust/PROJECTS/NEUTAG/data/MSR/msr_test_gold.utf8.delt.tag'\n",
    "\n",
    "TRAIN_DATA = pack(train_sentfile, train_tagfile)\n",
    "TEST_DATA = pack(test_sentfile, test_tagfile)\n",
    "\n",
    "import pickle\n",
    "dumppath = train_sentfile.split('_')[0] + '_data.pkl'\n",
    "pickle.dump([TRAIN_DATA, TEST_DATA], open(dumppath, \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-09T12:25:23.843092Z",
     "start_time": "2018-08-09T12:25:23.744697Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59\n",
      "56\n"
     ]
    }
   ],
   "source": [
    "print(max([len(i[0]) for i in TRAIN_DATA]))\n",
    "print(max([len(i[0]) for i in TEST_DATA]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-09T12:25:33.863665Z",
     "start_time": "2018-08-09T12:25:29.463320Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "710153\n",
      "(['時', '間', '：'], ['B', 'E', 'U'])\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "# path = '/home/faust/PROJECTS/NEUTAG/data/PKU/pku_data.pkl'\n",
    "path = '/home/faust/PROJECTS/NEUTAG/data/AS/as_data.pkl'\n",
    "# path = '/home/faust/PROJECTS/NEUTAG/data/MSR/msr_data.pkl'\n",
    "# path = '/home/faust/PROJECTS/NEUTAG/data/CITYU/cityu_data.pkl'\n",
    "TRAIN_DATA, TEST_DATA = pickle.load(open(path, 'rb'))\n",
    "print(len(TRAIN_DATA))\n",
    "print(TRAIN_DATA[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-01T07:07:03.416785Z",
     "start_time": "2018-08-01T07:07:01.505473Z"
    }
   },
   "outputs": [],
   "source": [
    "from gensim import corpora\n",
    "def cchars(data):\n",
    "    chars = [i[0] for i in data]\n",
    "    dictionary = corpora.Dictionary(chars)\n",
    "    return list(dictionary.values())\n",
    "\n",
    "dicts = cchars(TRAIN_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-01T09:35:40.029675Z",
     "start_time": "2018-08-01T09:35:40.017323Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dicts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-b19eb284a9f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdicts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# print(dicts)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dicts' is not defined"
     ]
    }
   ],
   "source": [
    "print(len(dicts))\n",
    "# print(dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-01T13:58:52.229139Z",
     "start_time": "2018-08-01T13:58:51.954072Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['」', '說', '到', '此', '楊', '已', '忍', '不', '住', '嗚', '咽', '。']\n",
      "['B', 'E', 'U', 'U', 'U', 'U', 'B', 'I', 'E', 'B', 'E', 'U']\n",
      "['」說', '到', '此', '楊', '已', '忍不住', '嗚咽', '。']\n",
      "['」', '說', '到此', '楊', '已', '忍不住', '嗚咽', '。']\n"
     ]
    }
   ],
   "source": [
    "sent = TRAIN_DATA[100][0]\n",
    "tags = TRAIN_DATA[100][1]\n",
    "print(sent)\n",
    "print(tags)\n",
    "\n",
    "tagset = ['B', 'I', 'E', 'U']\n",
    "\n",
    "def parsetags(sent, tseq):\n",
    "    result = ''\n",
    "    binlist = tag2bin(tseq)\n",
    "    for i, b in enumerate(binlist):\n",
    "        if b == 0:\n",
    "            result += '#|#'\n",
    "            result += sent[i]\n",
    "        else:\n",
    "            result += sent[i]\n",
    "    segs = result.split('#|#')\n",
    "    segs = [s for s in segs if len(s) > 0]\n",
    "#     print(segs)\n",
    "    return segs\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "def tag2bin(tseq):\n",
    "    result = [int(t in ['I', 'E']) for t in tseq]\n",
    "#     print(result)\n",
    "    return result\n",
    "\n",
    "\n",
    "def bin2tag(bseq):\n",
    "    result = []\n",
    "    for i in range(len(bseq)-1):\n",
    "        cur = bseq[i]\n",
    "        pst = bseq[i+1]\n",
    "        if cur == 0:\n",
    "            if pst == 0:\n",
    "                result.append('U')\n",
    "            else:\n",
    "                result.append('B')\n",
    "        else:\n",
    "            if pst == 0:\n",
    "                result.append('E')\n",
    "            else:\n",
    "                result.append('I')\n",
    "                \n",
    "    last = bseq[-1]\n",
    "    if last == 0:\n",
    "        result.append('U')\n",
    "    else:\n",
    "        result.append('E')\n",
    "#     print(result)\n",
    "    return result\n",
    "\n",
    "\n",
    "import random\n",
    "def negtseq(tseq, alpha=0.2):\n",
    "    nblist = tag2bin(tseq)\n",
    "    nn = max(int(len(tseq) * random.uniform(0.0, alpha)), 1)\n",
    "    rl = random.sample(range(len(tseq)), nn)\n",
    "    for i in range(len(tseq)):\n",
    "        if i in rl:\n",
    "            nblist[i] = 1 - nblist[i]\n",
    "    ntagseq = bin2tag(nblist)\n",
    "    return ntagseq\n",
    "    \n",
    "print(parsetags(sent, tags))\n",
    "ntags = negtseq(tags)\n",
    "print(parsetags(sent, ntags))\n",
    "# ntags = negtseq(tags, alpha=0.2)\n",
    "# print(parsetags(sent, ntags))\n",
    "# ntags = negtseq(tags, alpha=0.3)\n",
    "# print(parsetags(sent, ntags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-01T12:46:29.960860Z",
     "start_time": "2018-08-01T12:46:29.955107Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "s = '我是'\n",
    "print(re.findall(r'[a-z]+', s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-10T03:51:04.977212Z",
     "start_time": "2018-08-10T03:50:20.326208Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "352221 300\n",
      "\n",
      "145790\n"
     ]
    }
   ],
   "source": [
    "# import numpy as np\n",
    "# import re\n",
    "\n",
    "# def push_check(k, cdict2):\n",
    "#     flag = False\n",
    "#     if k[0] not in cdict2:\n",
    "#         cdict2[k[0]] = [k]\n",
    "#     else:\n",
    "#         if k not in cdict2[k[0]]:\n",
    "#             cdict2[k[0]].append(k)\n",
    "#         else:\n",
    "#             flag = True\n",
    "#     return flag\n",
    "\n",
    "\n",
    "# def loadc2v(path):\n",
    "#     with open(path, 'r', encoding='utf8') as f:\n",
    "#         embeddim = 0\n",
    "#         charlist = []\n",
    "#         embedlist = []\n",
    "#         cdict2order = {}\n",
    "        \n",
    "#         curi = 0\n",
    "#         for line in f:\n",
    "#             pieces = line.strip().split(' ')\n",
    "#             if curi == 0:\n",
    "#                 print(line)\n",
    "#                 embeddim = int(pieces[1])\n",
    "#             else:\n",
    "#                 k = pieces[0]\n",
    "#                 v = [float(i) for i in pieces[1:]]\n",
    "#                 if len(k) == 1 and k not in charlist:\n",
    "#                     charlist.append(k)\n",
    "#                     embedlist.append(v)\n",
    "# #                 if len(k) == 1 or (len(k) > 1 and len(re.findall(r'[a-z]+', k)) == 0):\n",
    "# #                     if not push_check(k, cdict2order):\n",
    "# #                         charlist.append(k)\n",
    "# #                         embedlist.append(v)\n",
    "#             curi += 1\n",
    "#     # OOV\n",
    "#     charlist.append('NONE')\n",
    "#     embedlist.append([0.00] * embeddim)\n",
    "#     charlist.append('OOV')\n",
    "#     embedlist.append([random.random() for i in range(embeddim)])\n",
    "#     print(len(charlist))\n",
    "#     print(len(embedlist))\n",
    "#     c2i = dict([(c,i) for i,c in enumerate(charlist)])\n",
    "#     emat = np.asarray(embedlist)\n",
    "#     return c2i, emat, embeddim\n",
    "    \n",
    "# path = '/home/faust/PROJECTS/NEUTAG/data/sgns.wiki.char'\n",
    "# c2i, emat, edim  = loadc2v(path)\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import re\n",
    "import random\n",
    "def loadc2v(path):\n",
    "    with open(path, 'r', encoding='utf8') as f:\n",
    "        embeddim = 0\n",
    "        gram2embed = {}\n",
    "        \n",
    "        cidx = 0  # 0 for padding\n",
    "        for line in f:\n",
    "            pieces = line.strip().split(' ')\n",
    "            if cidx == 0:\n",
    "                print(line)\n",
    "                embeddim = int(pieces[1])\n",
    "            else:\n",
    "                k = pieces[0]\n",
    "                v = [float(i) for i in pieces[1:]]\n",
    "                if len(k) == 1 or (len(k) == 2 and len(re.findall(r'[a-zA-Z]+', k)) == 0):\n",
    "                     gram2embed[k] = v\n",
    "            cidx += 1\n",
    "    # OOV\n",
    "    gram2embed['PAD'] = [0.00] * embeddim\n",
    "    gram2embed['OOV1'] = [random.random()] * embeddim\n",
    "    gram2embed['OOV2'] = [random.random()] * embeddim\n",
    "    print(len(gram2embed))\n",
    "          \n",
    "    c2i = {}\n",
    "    vlist = []\n",
    "    for idx, g2v in enumerate(gram2embed.items()):\n",
    "        g = g2v[0]\n",
    "        v = g2v[1]\n",
    "        c2i[g] = idx\n",
    "        vlist.append(v)\n",
    "    emat = np.asarray(vlist)\n",
    "    return c2i, emat, embeddim\n",
    "    \n",
    "path = '/home/faust/PROJECTS/NEUTAG/data/sgns.wiki.char'\n",
    "c2i, emat, edim  = loadc2v(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-10T03:51:58.864677Z",
     "start_time": "2018-08-10T03:51:58.859860Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n",
      "145790\n",
      "(145790, 300)\n",
      "300\n"
     ]
    }
   ],
   "source": [
    "# import random\n",
    "# print(random.random())\n",
    "\n",
    "# d = {'a': 1,\n",
    "#     'b': 2,\n",
    "#     'c': 3}\n",
    "# for x in enumerate(d.items()):\n",
    "#     print(x)\n",
    "print(edim)\n",
    "print(len(c2i))\n",
    "# print(c2i)\n",
    "print(emat.shape)\n",
    "print(len(emat[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-10T03:52:29.810568Z",
     "start_time": "2018-08-10T03:52:29.361664Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "dumppath = '/home/faust/PROJECTS/NEUTAG/data/gram2vec.pkl'\n",
    "pickle.dump([c2i, emat, edim], open(dumppath, \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-02T08:31:12.816960Z",
     "start_time": "2018-08-02T08:31:12.791606Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "dumppath = '/home/faust/PROJECTS/NEUTAG/data/gram2vec.pkl'\n",
    "c2i, emat, edim = pickle.load(open(dumppath, \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
